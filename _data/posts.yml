'2015-07-21':
  text: >
    This post is for those who work using SOA or other kind of distributed architecture.
    The biggest challenge for developers when working with this kind of architecture is to make development process as easy as possible. To achieve this goal there are a lot of tools but in this post I will show how to do that with [Tmux][t] and [Tmuxinator][tr]. 
    <br />
    <br />
    Requirements: `Mac OSX (~> 10.10.3), Brew (~> 0.9.5), Ruby (~> 2.2.2)`
    <br />
    Install Tmux: `brew install tmux`
    <br />
    Install Tmuxinator: `gem install tmuxinator`
    <br />
    Create tmuxinator project: [gist][g1]
    <br />
    Connect bash to tmux: download tmuxinator.bash [here][tb] and put it in `~/.bin` directory.
    <br />
    Add this to your `~/.bash_profile`: `source ~/.bin/tmuxinator.bash`
    <br />
    Run your project: `mux project_name`
    <br />
    <br />
    Now you have all your setup accessible via one bash command.
  hrefs:
    t: https://tmux.github.io
    tr: https://github.com/tmuxinator/tmuxinator
    g1: https://gist.github.com/e5f5c06b69a09bf6b3fc
    tb: https://raw.githubusercontent.com/tmuxinator/tmuxinator/master/completion/tmuxinator.bash

'2015-07-22':
  text: >
    <p>
      To be honest, last time I worked on a project based on SOA (Service Oriented Architecture) was a few years ago, but I think it's a good idea to share my 
      experience with it. There are a lot of advantages of SOA but for me these three are the most important: scaling, speed and decoupling.
    </p>
    <h2>Scaling</h2>
    <p>
       Scaling comes into play when your traffic grows. If you have monolithic application you can scale all of it independently of the parts that have high traffic.
       But this way is not efficient as unused parts of the project will eat your resources while scaling.
    </p>
    <p>SOA helps to scale only the needed parts of your project and keep the system efficient.</p>
    <h2>Speed</h2>
    <p>
       Small modular resources, optimized for particular role in a system, helps to achieve speed of accessing that resources and creates value by saving your customers 
       time. You need statistics? Create a service on top of MongoDB. Need to work with bank transactions? Create a service on top of RDBMS.</p>
    <h2>Decoupling</h2>
    <p>
       In general, decoupling is a good practice at any level of development. No one wants to work in a mess. It also serves very well when it comes to distributed 
       teams as you can control access of your services and divide development work to external teams without worrying that someone access not permitted data or code.
    </p>

'2015-07-24':
  text: >
    From the first days of my career as a programmer, I was using sophisticated and heavy tools for writing code. Actually, the first editor I tried was 
    [Adobe Dreamweaver][ad]. It's still alive and does its job quite well I suppose. Later on [TextMate][tm] which is one of my favorites code writing tools.
    A few months ago I tried [Atom][a] which is pretty nice too and comes with not so laggy text search as TextMate's.
    But this post is important not because of this story but because I've found a setup that makes me happy.
    
    <h2>Operating System</h2>
    <p>Let's be honest, the majority of medium experienced web developers like Mac OS X. I like it too. It's simple, beautiful for eye and is Unix family member.</p>
    <h2>Editor</h2>
    <p>Like mentioned in the intro, editor is the key for hapiness.</p>
    <p>
      Sometimes I catch myself thinking that web developer is a weak programmer. It's like a challenge and honor thing for each programmer to do as much cool stuff 
      as possible. However, I believe that there is a trade-off between cool stuff and the value you're really creating. To make it clear: not always cool stuff 
      creates more value.
    </p>
    But this post is about fun. Fun is to do something cool. Cool is something simple and easy. If you're a developer, probably you'd agree that the simpliest but 
    maybe not easiest editor is [Vim][v].
    When using Vim you use only keyboard to write, navigate and do other cool stuff. No mouse or trackpad clicking, just pure sound of your keyboard.
    As I'm a Ruby developer, [here's][s] the setup of Vim for rubyists on Mac OS X.
    
    <h2>Workflow</h2>
    Sometimes developers tend to overcomplicate things. This is why I like Ruby, although, it has it's own drawbacks too. Anyway, while writing any kind of code,
    it is important how do you manage your codebase and navigate across files while working.

    <p>Someone would say, just install some plugins to Vim and forget it. But this is not so efficient. Sounds weird but that's my opinion.</p>
    <p>If you need to switch among files a lot of times while working, that means that you're not following TDD/BDD and doing things with inertia, hurrying.</p>
    Good code takes time to write and think. Good naming helps to save time while connecting various bits of code and if you do this correctly, this kind of coding 
    starts to make sense.
    For code versioning I use [Git][g], editor - Vim, for file previewing, in case you need quickly look at some other than current Vim opened file - [Highlight][h]. 
    All these components are in separate Terminal tabs to make easier to navigate among those.
    
    <h2>Highlight</h2>
    <p>Sometimes while working on complicated part of application you need to view other files quickly. For this purpose I use Highlight.</p>

    Install Highlight: `brew install highlight`
    <br />
    Add alias to your `~/.bash_profile`: `alias c='highlight -O ansi -l'`
    <br />
    Usage: `c path/to/filename`

    <h2>Sum up</h2>
    <p>Although this works for me and helps to follow TDD/BDD practices, every developer has his/her own preferences. Happy coding!</p>
  hrefs:
    ad: http://www.adobe.com/products/dreamweaver.html
    tm: https://macromates.com
    a: https://atom.io
    v: http://www.vim.org
    s: https://gist.github.com/e4b526dffc109ab5384c
    g: https://git-scm.com
    h: http://www.andre-simon.de
  
'2015-10-04':
  text: >
    After installing [Tmux][t] I felt a bit confused. There is just plain "man" style documentation. I like things simple and explained clearly for a tool that is used by someone for the first time. Well that's not a big deal, I just needed to get deeper into the text and here is what I've found.
    
    <h2>Commands</h2>
    
    The first thing which was not clear to me was the switching among windows. To make that happen you need to use commands. Actually, that was not working at the beginning as I was missing `~./bin/tmuxinator.bash` file. Anyway, after some time I managed to figure out how to enter commands, switch among windows, split windows etc. To enter a command you need to use `Ctrl + b` and enter the command's character. [Here][h] is the list of commands.
    
    <h2>Sum up</h2>
    
    A bit pitty that there is no straight shortcuts like in Vim, but Tmux is still a handy tool for making things easier.
  hrefs:
    t: https://tmux.github.io
    h: 
'2015-08-02':
  text: >
    When working with Ruby together with team on a project, everyone should follow the same code standards to avoid mess and achieve better development speed. Usually, Ruby developers follow common rules and try to avoid rare operators, expressions and so on. But sometimes it's fun to play, explore and use variuos exotic Ruby capabilities to make development more interesting. 
    
    <h2>Standards</h2>
    
    <p>
      Usually, standards are pretty simple when it comes to editor configuration. 2 space soft tabs, tidy indentation and new line at the end of a file.
    </p>
      Proper code styling is a bit more sophisticated part. There are a lot of style guides that could be used by companies but I choose [Thoughbot][t] which is quite nice. If needed, of course, it can be adjusted by forking the repo.
    
    <p>
      Although it's good to follow standards, Ruby has a lot of power for fun.
    </p>

    <h2>Operators</h2>
   
    <p>
      If you're reading this blog, you should understand what are operators about and how to use them. Ruby has a lot of operators that can work independently among variuos kind of objects but in this blog post I'll mention just some interesting operators and use cases that could be used to have fun.
    </p> 

    <h3>*</h3>
    [Array#join][j] is a method for joining elements (String) to a row separated by the given argument. Example of usage:
    <br /><br /> 
    ```
    irb(main):001:0> ['a', 'b', 'c'].join(',')
    ```
    <br />
    ```
    => "a,b,c"
    ```
 
    <p>
      Shortcut <strong>*</strong> makes the syntax more fun:
    </p>
    ```
    irb(main):002:0> ['a', 'b', 'c'] * ','
    ```
    <br />
    ```=> "a,b,c"
    ```

    <h3>%</h3>
    [Numeric#modulo][m] is a math function which is very useful for arrays iterations when needed to insert something periodically into output.
    <br />
    Example:
    <br /> 
    ```irb(main):001:0> 22.modulo(10)```
    <br />
    ```=> 2```
   
    <p>
      Shortcut:
    </p>
    
    ```irb(main):002:0> 22 % 10```
    <br /> 
    ```=> 2```
  hrefs:
    m: http://ruby-doc.org/core-2.2.2/Numeric.html#method-i-modulo
    j: http://ruby-doc.org/core-2.2.2/Array.html#method-i-join
    t: https://github.com/thoughtbot/guides/tree/master/style/ruby 
'2015-08-05':
  text: >
    When starting to build a SOA (Service Oriented Architecture) project, sometimes it's hard to choose the right tools for it. 
    My first SOA project where I had a chance to participate was started a few years ago. 
    At that time there was no ready for production out-of-box solution for this kind of Ruby based systems. 
    Well, that was not a big problem for our team because we just builded the solution from scratch by ourselves.

    <h2>Blueprint</h2>

    The goal for our team was to create distributed, isolated and fast working architecture with capabilities for quick expansion. 
    It was needed to outsource some parts of the project for external teams, so the security was one of the main priorities.
    To achieve that, we needed to create something like [OAuth 1.0][o]. 
    It's a simple protocol which works very nicely when implementing together with concurrent requests for multiple resources fetching.
      
    <p>
     The schema below shows simplified version of the principle how it works.
    </p>

    <img src="/assets/img/soa-schema1.png" />

    <p>
      <strong>(1)</strong> - Before fetching resources (Service 1) must connect to Auth service and ask if it has permissions to operate on the Service 2.
      If it has, Auth provides authentication token to use for limited amount of time (30 mins etc) and, using that token <strong>(2)</strong>,
      Service 1 is able to connect to Service 2 and operate on the resources.
    </p> 

    <h2>Database structure</h2>
    The main architecture's structure is kept in Auth service as it decides about services communication security.
      
    <p>
     The fields in Auth <strong>clients</strong> table were these: <em>client_id, service_id, scope</em>.
     One more table was needed for the temporary access tokens, let's call it <strong>tokens</strong>: 
     <em>
       client_id (table's <strong>clients</strong> id), token, created_at
     </em>.
    </p>

    <h2>Client gem</h2>
       
    To make things faster and ease the communication among services including Auth gateway, we created a gem (not available as opensource anymore). 
    It includes caching of temporary tokens, concurrent HTTPS requests ([Typhoeus][t]) 
    and nice API for configuration of the services.

    <h2>Try yourself</h2>

    These days the situation is a bit different. I'm sure there are a lot of nice gems that could be combined together to achieve the same purpose.
    But before getting on this work, please read carefully about <a href="" target="_blank">[SOA][s]</a>
    and decide if it's a good choice for your project. Don't hesitate to use my proposed solution because it's pretty simple and you make sure that you know
    100% how your system works by doing the system from scratch.
  hrefs:
    o: http://oauth.net/core/1.0
    s: https://en.wikipedia.org/wiki/Service-oriented_architecture
    t: https://github.com/typhoeus/typhoeus
'2015-08-06':
  text: >
    Nowadays, there are a lot of hosting providers that offer variuos service packages in variuos regions. To be honest, it's a hard topic because the decision which hosting provider to choose very depends on business factors. Let's try to review some use cases and hosting providers.

    <h2>Small business / e-commerce shop</h2>
    
    Small electronic shops or representative webpages don't need to be placed on sophisticated hosting platforms. I'd recommend to choose <a href="https://en.wikipedia.org/wiki/Solid-state_drive" target="_blank">SSD</a> (storage) hosting for faster <a href="https://en.wikipedia.org/wiki/Input/output" target="_blank">I/O</a> and a hosting provider in the region where your business operate.
    
    <h2>Medium size / big e-commerce shops / PaaS / SaaS</h2>
    
    For such kind of projects, recommendation is to use <a href="https://en.wikipedia.org/wiki/Cloud_computing">Cloud-computing</a> or more specifically <a href="https://en.wikipedia.org/wiki/Platform_as_a_service" target="_blank">PaaS</a>. Some examples of such services: <a href="https://www.heroku.com" target="_blank">Heroku</a>, <a href="https://aws.amazon.com" target="_blank">AWS</a>, <a href="http://www.rackspace.com" target="_blank">RackSpace</a>.
    
    <h2>Projects with high security need</h2>
    
    If there is a project with very high security and uptime need, better place your own server somewhere in data center with the <a href="https://en.wikipedia.org/wiki/Service-level_agreement" target="_blank">SLA</a> which is acceptable for your business. Unfortunatelly, such cloud computing services as AWS or PaaS like Heroku (based on AWS cloud) sometimes is not stable 100% of the time, so please consider this option for very high SLA level.

    <h2>Some hosting providers</h2>
    
    Some providers that worth of trust: <a href="https://www.linode.com" target="_blank">Linode</a>, <a href="http://www.peer1.com" target="_blank">Peer1</a>, <a href="https://www.tilaa.com" target="_blank">Tilaa</a>. Before choosing any plan for hosting of any these, please read carefully SLAs and do not hesitate to search for a data center with your own separate server if your business has high security requirements.

    <h2>AWS</h2>
    
    Personally I like AWS because it offers space for creativity when it comes to sophisticated and distributed systems. If you are interested in creating something cool, big and fun, try it out. It comes with Database (<a href="https://aws.amazon.com/rds" target="_blank">RDS</a>), Caching (<a href="https://aws.amazon.com/elasticache/" target="_blank">ElastiCache</a>), Computing Cloud (<a href="https://aws.amazon.com/ec2" target="_blank">EC2</a>) and much more. Connecting all that parts gives a lot of fun!
  hrefs:
    
'2015-08-07':
  text: >
    If you're familiar with <a href="" target="_blank">Heroku</a>, you know how it's easy to manage deployments. Simple push to a <a href="" target="_blank">Git</a> repo and your deployment is in process. With <a href="" target="_blank">AWS</a> it's a bit different. This blog post will introduce you with simple way of creating similar homemade tool for easy deployments. Important to mention that AWS is much cheaper than Heroku. 

    <h2>Concepts</h2>
    <strong>AWS</strong> is a tool designed to give as much space for dynamic resources manipulation as possible. This allows developers to create products designed for exact business needs and avoid waste.
    
    <p>
      <strong>EC2</strong> is a service that allows developers to operate on cloud computing resources (create EC2 instances and put there your application to be accessible from outside). 
    </p>
    <p>
      <strong>RDS</strong> is a service that allows to create data store instances.
    </p>
    <p>
      <strong>CloudFormation</strong> is a tool that connects all AWS services and allows to create / edit / delete instances of specified services. In simple words, it allows to create necessary EC2 / RDS / ElastiCache instances for application by one take and later modify that if needed.
    </p>

    <h2>Blueprint</h2>
    
    The scheme below shows how the deployment PaaS works. It's pretty straightforward but needs some Ruby based implementation tools to create all the stack easily.
    <br /><br />
    <img src="/assets/img/deployment-paas1.png" />
    <br /><br />
      <strong>(1)</strong> - you hit the EC2 instance which is responsible for deploys (connected to a small RDS for deployment related data) via HTTPS with parameters which application to deploy. The PaaS contains CloudFormation scripts for each application. In this case, the deployment request is made for <strong>application 2</strong> which has a RDS instance attached, so when the request comes from your local machine to PaaS, it chooses CloudFormation script specific for the chosen application and starts deployment <strong>(2)</strong>. 
    <p>
     As you can see, <strong>application 1</strong> has no RDS instance attached, therefore it has a different CloudFormation script and is ready to be deployed if PaaS gets a request to do that.
    </p>

    <h2>Implementation</h2>
    
    <p>
      There are some handy tools writen in Ruby to make this scheme working, but default <a href="https://aws.amazon.com/cli" target="_blank">AWS CLI</a> tools are also needed.
    </p>
    <p>
     Please check out <a href="https://github.com/ThoughtWorksStudios/eb_deployer" target="_blank">EB deployer</a> which helps to create application stacks using <a href="http://aws.amazon.com/elasticbeanstalk" target="_blank">Elastic Beanstalk</a> and supports CloudFormation scripts to operate on multiple types of AWS services.
    </p>
    <p>
      The main implementation happens in the PaaS as it will store all the configuration details for each application and just give commands to ElasticBeanstalk and CloudFormation services to create stacks for each application.
    </p>

    <h2>Some ideas</h2>
    When you will have the initial version of this PaaS working, you can add to it whatever you want: HTTPS based logs, DB backups, periodical events (deploys, db backups), more advanced HTTPS API for making the service more easy to use. Unfortunatelly, the current version of this PaaS that I have access to is not ready for production, so please do it by yourself, share and maybe one day we'll merge our ideas to make this open source for everyone. Cheers!
  hrefs:
    
'2015-08-08':
  text: >
    <a href="https://aws.amazon.com/elasticbeanstalk"  target="_blank">Elastic Beanstalk</a> is a AWS service which helps to ease deployments of applications. Often we need to deploy applications without downtime and have failover which is always ready to be used to make sure the system stays operational all the time. Elastic Beanstalk is exactly designed for this purpose. This blog post will review the main features of this service and help you to get better understanding of robust and easy deployments with AWS.

    <h2>Deployment strategies</h2>
    
    Elastic Beanstalk supports multiple deployment strategies, load balancing and all other cool stuff that allows you to forget about details that is not very important for your product development.
    
    <h3>In place deployment</h3>
    In place deployment is a bit risky strategy of EB. It's fast from that perspective, that you work only with one EB instance but started deployment is running while your production environment is online. This is not too bad for low load having applications but if your product has high traffic, it may occur some unexpected errors and you won't have failover to manage the accident.
    
    <h3>Blue Green deployment</h3>
    This strategy is better for high-medium traffic having applications. The principle is simple: you have two EB instances and when performing a deploy, one of those is still active (with all EC2 instances). After deployment has been done, the instances' CNAMEs are switched and the deployed version of application goes live.

    <h2>Deployment security</h2>
   
      When performing deploys, in EB instance settings you can define HTTP(S) check URL. It is recommended to use it to make sure your deployed EB instance is responsive from outside. In this way EB core determines if deployed EB instance is available for the switch (Blue Green) or just available (In place).
    <p>
      If something bads happen, Blue Green deploy has the advantage of failover and ability to switch the EB instances manually by using AWS interface or CLI. In theory, if application has been built correctly, this should never happen.
    </p>
    
    <h2>Final word</h2>
      To be honest, I like Elastic Beanstalk for its simplicity and capabilities. If you're starting to build something standard, you should choose it together with the <a href="http://docs.aws.amazon.com/elasticbeanstalk/latest/dg/concepts.platforms.html" target="_blank">supported development platforms</a>. For more advanced systems with more sophisticated purposes, please consider using <a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/AMIs.html" target="_blank">Amazon Machine Images (AMI)</a> which allows to build your custom EC2 instances and of course use for scaling like Elastic Beanstalk.

  hrefs:
    
'2015-08-11':
  text: >
    <a href='https://aws.amazon.com/rds' target='_blank'>AWS RDS</a> is a service for data store. It has a lot of cool features, like periodic data server snapshots, monitoring, a lot of security options and so on. The problem with it comes out when you need to switch to a different provider or do some data migration for a specific database in an instance. Currently this feature is not supported natively, so this blog post is about how to make a work around. If you need a simple DB backup from your RDS instance, please keep reading.
    
    <h2>Blueprint</h2>
    
    <ol>
      <li>From your application console, rake task or application gem hits the RDS instance to create a clone of it.</li>
      <li>The duplicate of the instance starts to be created, it takes some time depending on your RDS instance size, type etc.</li>
      <li>After the temporary RDS instance is created, the application fetches a chosen database to localhost (mysqldump, pg_dump etc.) and uploads it to a <a href='https://aws.amazon.com/s3' target='_blank'>S3</a> bucket where it is protected by S3 security policies.</li>
      <li>Now your local machine or any kind of other server can fetch the DB backup from S3.</li>
    </ol>
    
    <p>
      After the DB backup creation process completes, the temporary RDS instance is shutdown to save the cost of the operation.
    </p>
   
     <h2>The gem</h2>
      Somewhere on the internet this kind of work around has already been described but it's just a pure list of bash commands. To make things easier, I've created a Ruby <a href='https://github.com/kurbaitis/rds_db_backup' target='_blank'>gem</a> which is currently at beta version stage so please don't hesitate to fork it and send pull requests.

  hrefs:
    
'2015-08-23':
  text: >
    <a href="https://digitalocean.com" target="_blank">DigitalOcean</a> is a cloud computing service which has amazingly beautiful API for all resources administration.

    <h2>Structure</h2>
      The service has a lot of cool features, but I'll mention just two the most important ones for me: Droplets (server instances) and Images (inactive server stacks for scaling).
    
    <p>
      <strong>Droplets</strong> - is a service for server instances, it allows to create instances based on some predefined stacks that is very handy for creating specialized instances for data store, caching or load balancing etc. It also supports multiple regions to make your application faster for clients.<br />
      <strong>Images</strong> - is a service for creating "templates" based on created Droplets. These created stacks that can contain your own modifications are useful for scaling your application.
    </p>
    
    <h2>The gem</h2>

    There is <a href="https://github.com/rmoriz/knife-digital_ocean" target="_blank">a Ruby gem</a> for the API but it works only using console so I modified it to be used directly from Ruby interface. It's not perfect due to the lack of time so please consider forking and improving it. Please check it out <a href="https://github.com/kurbaitis/knife-digital_ocean" target="_blank">here</a>.

  hrefs:
    
'2015-08-26':
  text: >
    This blog post will be a bit different than the ones before because I won't mention any big data centers or optimization recipes etc. This blog post is about serious stuff. No micky mouse stuff about beautiful frontend, javascript or whatever. After 11-12 years of working as a programmer, I slowly started to understand one thing: no matter what, your client must go through your created process as fast as possible and without any distractions. To achieve this, you don't need powerful hardware, application architecture or whatever. I'd like to share some thoughts about simplicity of system architecture that comes to probably each developer's brains at some point. 

    <h2>Hardware</h2>
      
    Did you notice where all world is going to with such technology development speed? Yes, it's evolution, we all know that there is no way back, but there is a better way which leads to true love of development work for developers and to time saving for the clients. 
    
    <p>
      Well, let's start from storage, one word: SSD. No more burning HDD or playing with RAID. It's just not efficient from all perspectives.
    </p>
    <p>
      No matter what internet connection or hardware you have, the end point is your ethernet adapter throughput which determines how many clients you can serve. Try to find the best option with the biggest throughput. There are just some limits in this world when it comes to effective technologies. This is where the load balancing and scaling comes into play. In short: just give some cash for capitalists if you don't know what you're doing.
    </p>
    <p>
      Processor doesn't matter too much as long as you choose appropriate programming language and know how to use it properly. 
    </p>

    <h2>OS</h2>
    
    Ideally, developers could use an operating system which would be designed exactly for HTTP. But I haven't heard about any of these so far. Double check please, if you can't find it, then MIT is just making jokes of earth resources.
   
    <p>
      Ok, plan B: use one of BSD family operating systems.
    </p>

    <h2>Programming language</h2>

    I have to confess, I'm biased when it comes to programming language because I love Ruby for simplicity. Some of you can say that it's too slow or not efficient. I disagree. If you build systems based on the simplicity principles, there should not be any problems to achieve efficiency of development and needed performance. Just don't overcomplicate things at the beginning and maybe later rewrite everything on native operating system language (Assembler could work too if you know what I mean). 

    <h2>Frontend</h2>
   
    For my last project I used one of those responsive CSS/JS frameworks that could have been not needed if technology would took more standards based way of development. Seriuosly: if a country produce its technology (cell phones, laptops, tablets) why to export to other countries and make more mess in all the world when it comes to efficiency? More standards - more shitty workarounds for all developers and more cash for clients. Not purposeful.
    
    <p>
      Anyway, we have what we have. The best what you can do is to try to build a website based on simple HTML and tables which provides you with home made responsive templates.
    </p>

    <h2>Final thoughts</h2>
   
    When you work on something, you put your heart into the work. Your heart belongs to what you believe. I believe in specialization and effective resources usage.

    <p>
      Hopefully, one day there will be one hardware, one OS and one programming language for web development. If that would be kept in the biggest data center in the world, that would be a revolution in IT which would help to save energy for all sides (developer - client). Anyway, don't think about this too much, it's our time to have fun with all that different standards and all that security traps. Cheers!
    </p>

  hrefs:
    
'2015-08-31':
  text: >
    Usually in web development everyone is using HTTP servers like <a href="http://apache.org" target="_blank">Apache</a> of <a href="http://nginx.org" target="_blank">Nginx</a>, of course with HTTPS support if needed. In short: it's wasteful. In this blog post I'll introduce you with some useful open source Ruby products that can be used as a standalone HTTP(S) servers.

    <h2>Web frameworks</h2>
    
    In my opinion there are three decent Ruby web frameworks that are useful for separate purposes: <a href="http://rubyonrails.org" target="_blank">Rails</a> (beautiful frontend products), <a href="http://www.sinatrarb.com" target="_blank">Sinatra</a> (simple and easy to use products), <a href="http://intridea.github.io/grape" target="_blank">Grape</a> (mostly for APIs, decide yourself if you need that). All of these have <a href="http://rack.github.io" target="_blank">Rack</a> gem inside which is placed on top of HTTP(S) server (<a href="http://ruby-doc.org/stdlib-2.0.0/libdoc/webrick/rdoc/WEBrick.html" target="_blank">WEBrick</a>, <a href="http://code.macournoyer.com/thin" target="_blank">Thin</a>, <a href="https://github.com/mongrel/mongrel" target="_blank">Mongrel</a> etc.) and all that stack successfully runs together. It's a bit pitty that there is no common standard for all needs together, but that's a different story.
    
    <h3>WEBrick</h3>
    WEBrick is the default server for Rails and Sinatra for sure, please check if Grape is using the same if you're interested in SOA.
    
    <p>
      Well, it took a bit of time to setup WEBrick on Sinatra with HTTPS support for me but finally I made it work. The problem is that when there are multiple layers for one purpose, you have to connect all parts and it takes your precious time, however, it's a kind of fun.
    </p>
  
    <h3>Thin</h3>

    To be honest, I tried Thin too but for HTTPS it didn't work out. Maybe for HTTP it's good but we're currently not in perfect world so if you try to make a secure product, please choose WEBrick or any other web server that works for you. However, Thin also supports Vhosts that allows to run multiple sites on the same IP, please be careful with that because it's not secure and not efficient.

    <h2>Some thoughs</h2>
    
    Like it's mentioned in the last blog post, I'm working on a small product which will be released as an open source framework for any kind of products selling online but initially it is being created for game servers hosting services.
    
    <p>
      Comming back to the "ideal world" idea is that currently Ruby community has some problems with making things simple and oriented to one direction. Yes, Rails became like a brand of Ruby and the language itself is known as a web development tool but there is no strict leadership and limits to publify gems or products which leads to a lot of standards, not useful gems and tools. Anyway, those who know how to work with Ruby, will find their way to easy development, wish you that and don't forget to check out the release that I'm working on at the moment.
    </p>

  hrefs:
    
'2015-09-01':
  text: >
    <a href='https://en.wikipedia.org/wiki/Transport_Layer_Security' target='_blank'>SSL</a> or TLS (more modern version) is a handy tool to protect yourself from mid-level hackers. Well, relatively. There is no protection from experienced hackers that can play with your data. Why? Simply because there is the 2nd party that provides you with the certificate. However, it's better to protect yourself from that mid-level hackers. For my project, I bought the certificate from my favorite Lithuanian hosting provider which basically is just reselling <a href='https://www.comodo.com' target='_blank'>Comodo</a> certificates. Anyway, everyone should support its country, right?

    <h2>Unix environment</h2>
    
    I like <a href='https://en.wikipedia.org/wiki/Unix' target='_blank'>Unix</a> family OSes, every developer likes because it's simple, robust and fast. But not so secure as everyone is thinking. It's again about focusing. Multiple users systems are desinged for making mistakes and hassle. Even if you want to bind low level ports to your application with not root user, you encounter a problem. There are workarounds, but it's just a game again, hopefully experienced hacker will give you some mercy and leave the system the same as it was before entering it if you make things at least clean and right.
    
    <h2>The workaround</h2>
    
    The workaround I'm using is called <a href='http://linux.die.net/man/8/setcap' target='_blank'>setcap</a>. It's a <a href='https://www.debian.org' target='_blank'>Debian</a> package which provides you with ability to permit low level ports for any user in your system.
    
    <h2>What is recommended</h2>

    Again, all the documentation for developers are complicated. It says that if you install any software, you shouldn't run it on root user. But you still need root user by default to run your applications. Anyway, just after some time when you get used to the Unix tools you start to understand, that it has some problems with efficiency and security. Hopefully one day that will change. Until that all beginner developers are just destroying their eye vision.

  hrefs:
    
'2015-09-04':
  text: >
    Before making my first serious product release, I started to think about my way to this level of programming mastery. It took me around 11 years to get the necessary skills for making good software. Anyway, better to start earlier than never. As it seems I'm 25 years old now, I can share some thoughts how to become a good programmer, no matter what language.

    <h2>Education</h2>
    
    Not needed. Well, at least high school or something what belongs to you by law. Simple and efficient, everything what you need is in your pocket. If you work, better use computer of course.
    
    <h2>Values</h2>
    
    Not everyone can be a good software engineer, it must be in your blood. It's a bit like art and some physics to make everything efficient. But simple enough to learn for everyone. The inner software engineer values must be balanced. Your character must be very pragmatic. But you get your dose of fun when reach the goal and make your program to work. This is the true hapiness for each true, no matter, a software engineer, or just a developer.
   
    <h2>Life</h2>
    
    It sucks because your brains are growing like on steroids. Usually you don't have to talk about anything with your mates. Believe me, I've tried studying international business and it doesn't help. Still nothing to get from others. Just boring talks about the same things. If you have kids, better don't teach them programming early. They might become mental if not possible to switch to other occupations.
    
    <h2>Technical development</h2>
  
    Well, it's my personal opinion, but you must become a good programmer at first. You can't just start from getting deep into OSes while not knowing how to write software properly. But it's just recommendation. Mobile applications: wasteful. If you respect your forests in your country, please stick to HTTP(S). WEB is so far the most balanced decision to use for all kind of devices.
    
    <h2>The secret</h2>
    
    Writing software is interesting, writing it good also, but at some point you start to understand, that you must write it by giving 100% of yourself because it's the only way to respect your 11 years of wasting eye vision. But don't start to read books if you're a beginner. Start slowly, experiment, make mistakes, have fun, start to love coding.
  
    <h2>Sum up</h2>

    It's all about the balance in life, sometimes it's harder, sometimes it's easier. The most important thing that you do what you're born to do. Better to start search for your way earlier than never. Time for a smoke... 

  hrefs:
    
'2015-09-03':
  text: >
    As I promised to release the game hosting engine, in this blog post I'll share some details about it. The main goal was to make it as secure and simple as possible. Anyway, it took a lot of time to come up with a balanced solution which will provide players/hosters with very nice tool to make game hosting services easy to use. 

    <h2>Security</h2>
    
     The security layer in the product, as I've mentioned before, is simple and standard: everywhere <a href='https://tools.ietf.org/html/rfc5246' target='_blank'>TLS v1.2</a>. It uses the protocol for <a href='http://dev.maxmind.com/geoip/legacy/geolite'>GeoIP</a> data fetching, payments, error reporting and data centers connection.
    
    <h2>Error reporting</h2>
  
    For error reporting I've chosen <a href='https://www.twilio.com' target='_blank'>Twilio</a> which is well known for everyone. It supports voice and SMS messaging, but for now I've chosen just SMS reporting as it provides the product with everything what it needs: file path and line number which is responsible for the error. As the encapsulation is proper, this amount of information is enough to find the mistake. If error occurs, the report is sent to defined mobile phone and the HTTP/HTTPS server is shut down to make sure that no one will hit the same bug again.
    
    <h2>Database</h2>
    
    No database. Thanks to <a href='https://stripe.com' target='_blank'>Stripe</a> which it seems works fine at least with my credit card (<a href='https://usa.visa.com/personal/cards/debit' target='_blank'>Visa Debit</a>).
    
    <h2>Logging</h2>
    
    Logging is optional as almost everything in the system. You can define where to log, for now it just logs to /dev/null (nowhere).
    
    <h2>Interface</h2>
    
    Simple tables which gives responsivness. No JavaSript (well just for some social networks share buttons).
    
    <h2>Sum up</h2>

    The product will be shared on GitHub but the prototype will be hosted on my side. Hopefully, I'll finish this job in a few days. Until that time, please comment, suggest ideas and help me to make this product more beautiful.

  hrefs:
    
'2015-09-05':
  text: >
    Finally, I've just uploaded the source to <a href='https://github.com/kurbaitis/hosting' target='_blank'>GitHub</a>. To make it work you need to read the README, setup the dependencies and configure your .env file which will provide you with some knowledge how the product is working. Don't hesitate to explore the source code as it would be nice to get some help for making this project beautiful. 

    <h2>The .env file</h2>
    
    Check it out [here][h] please.
    
    <h2>Notes</h2>
    
    To get better understanding, if it's hard to see from the source and the .env file, please take a look at <a href='/2015/09/03/The-preview-of-hosting-engine.html' target='_blank'>the preview blog post</a>.
    
    <h2>Demo</h2>
    
    To see how the project works, please go to <a href='https://hosting.games-monitor.net' target='_blank'>this page</a>. [Credentials for the payment][p]:

  hrefs:
    h: https://gist.github.com/78e3de3b63f7f4e4619e
    p: https://gist.github.com/e9b415bd783eaa3de152
'2015-09-06':
  text: >
    Well, information is simple thing. Input and output. It can be various. If you have neighbours, you can give some information to them. For instance, go out and have a smoke. If your neighboar sees that, he might also go out and have a smoke. Or he can come and have a smoke together. Anyway, in IT it's more complicated and the reason is globalization which needs additional resources for usability, for users and so on. Everyone wants easy access to resources.

    <h2>HTTP(S)</h2>
    
    The same principle is in HTTP(S) servers. There a lot of standards builded on top of it: <a href='https://en.wikipedia.org/wiki/Representational_state_transfer' target='_blank'>REST</a>, <a href='https://en.wikipedia.org/wiki/SOAP' target='_blank'>SOAP</a>, <a href='https://en.wikipedia.org/wiki/XML' target='_blank'>XML</a> and so on. Again we're not in perfect world. To be honest, I like <a href='https://github.com/eventmachine/eventmachine' target='_blank'>EventMachine</a> which provides you with unstoppable core which is based on events. You can even choose what protocol to use for I/O: TCPSocket, UDPSocket, OpenSSLSocket and so on. Anyway, if you know Ruby enough, you can construct your own home made event machine based on <a href='https://en.wikipedia.org/wiki/Reactor_pattern' target='_blank'>Reactor</a> pattern. It's a bit risky to do that because Ruby might have dangerious stuff inside and it depends on specific versions of it.
    
    <h2>Sum up</h2>
    
    The sum up is very simple: to satisfy users and keep everyone happy, IT is based on HTTP(S) standard as the I/O tool. Well, at least for now because maybe one day this gonna change. When it comes to mobile applications, usually those are also dependent on HTTP(S) protocol which is a bit inneficient like I mentioned in some previous blog posts.
  hrefs:
    
'2015-09-12':
  text: >
   
    <a href='http://bundler.io' target='_blank'>Bundler</a> is a powerful tool to manage <a href='https://rubygems.org' target='_blank'>Rubygems</a> dependencies. Well for complex systems with a requirement to provide clients with beautiful interface, it works fine, but for simple systems it's better to use the default Rubygems way. In this blog post you'll see how it's easy to use <a href='http://ruby-doc.org/core-2.2.3/ENV.html' target='_blank'>ENV</a> constant to fetch the dependencies list and require those.

    <h2>The variables</h2>
    The variables are set in ```.env``` file like [this][t]. You can use [dotenv][d] gem to require that variables. 
    
    <p>
      The first line defines gem names from the default Rubygems database. The second line defines the order and naming of the require files.
    </p>
    
    <h2>The require</h2>
    
    There are a lot of ways to require a gem but I choose the simpliest one:
    <br />
    ```ENV.fetch('R').split('.').each(&method(:require))```

  hrefs:
    d: https://github.com/bkeepers/dotenv
    t: https://gist.github.com/a21a6eb2cbde13f5ed65
'2015-09-13':
  text: >
    The initial purpose of IT is to ease the process. Sometimes it's hard to do that with wrong tools and there are a lot of wrong tools. Anyway, each developer should work towards making that tools easier to use or create his/her own tools and share. It's not possible just to dump all the software dedicated to WEB and start from scratch but it's possible to make that tools work nicely together.

    <h2>Decoupling</h2>
      
    One of the things that I've learned during my long career in IT is that you need to decouple things, that makes things easier for the future. Decoupling comes to various levels of the system: users system, publishing tools, development tools and finally code. For instance: why you need always to ask permissions from root user in Unix? That's not efficient, better use one user: setup with root user and work with your new created user.
    
    <h2>In practice</h2>
    
    There is a good example which I like - <a href='https://rvm.io' target='_blank'>RVM</a>. It's a powerful tool for Ruby versions management but you decide if it's really needed. Anyway, I like RVM because of the ease of install. One command and you're ready to go.
    
    <h2>The backend</h2>

    Unfortunatelly, the problem with that tools is the backend which might be complicated because it tries to support a lot of kind of systems. Think better to build your tool and define strict requirements for it. Just to make your system efficient.

  hrefs:
    
'2015-09-15':
  text: >
    Unexpectedly, it seems my experimental project is ready to be released again. In the previous post I've mentioned some fixes and todo's that should be added later on. Please take a look at the <a href='/2015/09/05/The-release.html' target='_blank'>first release notes</a> to understand how the project works. However, this version requires a bit different configuration, you'll find the sample .env file in the source after setup.

    <h2>Demo</h2>
 
    The demo could be found <a href='https://hosting.games-monitor.net' target='_blank'>here</a>. The credentials of the credit card is in the first release blog post.

    <h2>Sum up</h2>

    Don't forget to check out the source, suggest improvements and so on. It's an exciting experiment which helps to understand Ruby better, hopefully, for you too.

  hrefs:
    
'2015-09-16':
  text: >
    This release has a lot of improvements which includes some decoupling. Like I mentioned in the last blog post, decoupling is the key to easy further development. The purpose of the project is to decouple as much levels as possible and get to the point where you need only <a href='https://www.gnu.org/software/bash' target='_blank'>Bash</a> and <a href='https://ruby-lang.org' target='_blank'>Ruby</a>. But that's for the future.

    <h2>Crontab</h2>
      The first release contains <a href='http://crontab.org' target='_blank'>Crontab</a> which is a bit not stable when it comes to <a href='https://en.wikipedia.org/wiki/POSIX' target='_blank'>POSIX</a> users switching. Why not to do it [with Ruby][wr]:
    
    <p>
      In this way, the geographical location database is updated each hour and the script is non-blocking.
    </p>

    <h2>Github</h2>
    
    It's a good idea to decouple from <a href='https://github.com' target='_blank'>Github</a> when it comes to installation. The only thing you need from it is <a href='https://help.github.com/articles/creating-an-access-token-for-command-line-use' target='_blank'>Access Token</a> which provides you with ability to work with Github probably the same like using the website. By using this one line you can install essential packages for installing your application and execute application's install script.
    <br />
    <br />    
    ```t='86be456829f0e8645ab7c6bc36f495f518ed8f65' && apt-get install -y curl ca-certificates && curl -H "Authorization: token $t" -H 'Accept: application/vnd.github.v3.raw' -O -L https://api.github.com/repos/username/your-repo/contents/public/s && bash s $t```

    <p>
      So the thing here is that you just get from Github the bash installation script and it does everything what you need before configuration. Hopefully the next release will have ability to put all the credentials in one line and the script will do it's work.
    </p>

    <h2>TLS</h2>

    For the testing purposes I bought the cheapest <a href='' target='_blank'>TLS v1.2</a> certificate which has some security issues when working together with Ruby. But please try to use different one and let me know if it works fine.

    <h2>V2</h2>
    The release is on its way, hopefully I'll finish it today or tomorrow. Cheers.

  hrefs:
    wr: https://gist.github.com/388cc26b76a7ac9e40cd 
'2015-09-17':
  text: >
    <a href='https://www.openssl.org' target='_blank'>OpenSSL</a> is a tool for managing SSL/TLS connections. Well it still has some issues when it comes to support of newest standards but it's bearable. The implementation of OpenSSL in Ruby is complicated too due to the same reason. However, there are some ways to workaround the issues that personally I've encountered with <a href='https://www.comodo.com' target='_blank'>Comodo</a> TLS 1.2 certificate.

    <h2>Testing</h2>

    Like I've mentioned in some older posts, for the experiment I'm using <a href='https://github.com/nahi/webrick' target='_blank'>WEBrick</a> HTTP(S) server which comes with SSL/TLS support. All the configuration is decoupled to the .env file, so it's easy to test. WEBrick supports a lot of OpenSSL configuration details but not all needed. If you're setting up WEBrick SSL/TLS server, please also use your certificate provider's tool for testing the connection.

    <p>
    The results of my case had some problems. In short: Microsoft software trust, multiple SSL/TLS versions support, Ciphers, secure renegotiation (client-side).
    As you probably understand, this kind of issues are potential threats for the system.
    </p>

    <h2>Some workarounds</h2>
    
    1) Compile openssl library manually for Ruby to use the newest version of it
    <br />
    2) Instead of ca-certificates lib, use <a href='http://curl.haxx.se/ca/cacert.pem' target='_blank'>this cert</a>
    <br />
    3) [Configure WEBrick][cw]
    
    <p>
      As you can see, mostly all the configuration is fetched from ENV constant. Although WEBrick is a powerful tool it lacks two configuration options: ssl_version and ciphers. It's a bit of hack to fix it like this. But not needed if you compile your OpenSSL with defined ciphers by default.
    </p>
    <p>
      The only bug which I haven't fixed yet is the Secure renegotiation (client-side) which refers to a TLS extension <a href='https://tools.ietf.org/html/rfc5746'>RFC 5746</a> which is the solution for this bug in the default OpenSSL implementation. There is a workaround described in Ruby documentation but it haven't worked for me, maybe because my certificate is chained. Anyway, currently I'm trying other kind of workarounds and hopefully soon will solve this issue without any hacks and the default WEBrick source code.
    </p>

  hrefs:
    cw: https://gist.github.com/kurbaitis/a864be74520329202fb3
'2015-09-20':
  text: >
    This blog post is about the simplicity of creating pure Ruby based websites. Actually, everything what you need for creating a website without connected 3rd parties is in default Ruby build source. WEBrick with ERB and CGI (legacy) support gives you a lot of power to build simple, easy to use and reliable websites (if you know how Ruby works and write code respectfully).

    <h2>The issue</h2>
    
    Like I've mentioned in earlier blog posts, the problem with website usability is simple: there are just too many stuff and options for a customer. If you do things right, you focus and provide services that are exactly for the segment which you're targeting to. Less hassle, less pain for everyone.
    
    <p>
      If you follow this philosophy of single segment orientation, it's very easy to create a simple site for your products or other kind of value selling. It's harder to make all the necessary services (payments, monitoring, scaling) to work properly and neatly. This needs a bit more understanding in other concepts like encapsulation, decoupling, security and so on. While working on my experiment, I'm doing some thinking how to make things easier by removing some dependencies. This is where native Ruby libraries comes into play.
    </p>
  
    <h2>Sinatra</h2>
    
    Sinatra is a beautiful framework (a separate gem), but I'm not sure about its long term capabilities to manage traffic. Ruby is leaking memory if you create a lot of objects and do not use GC properly. If you want to write a beautiful Sinatra based application, you need to use a lot of objects and also it adds additional level to your application stack: Rack -> WEBrick -> Sinatra. Well, I don't want to spare a lot of time for investigating that layers compatibility issues and GC. Better think something simplier and use local variables that are not so hard to manage for Ruby: this is what I'm doing in my experiment.
  
    <h2>My try</h2>
      
    The thing I'm trying currently is to use pure WEBrick server which is included by default in Ruby build source. Recently, I discovered that it supports mounting all needed routes directly to given templates. The variables (from 3rd party apps too) get forwarded from lib/ level and templates just print out the final views. The implementation [files][f].
    
    <p>
      The issue here is that you need to pass current variables scope (binding) to the lib/ level. Well, it's a bit pain if you don't want to create additional instances and use just functional programming. But maybe there is another way. 
    </p>
    
    <h2>Sum up</h2>
    
    <p>
      So this post is about a bit different approach: logic in lib/, routing in app.rb and the templates in views/. No mixing anything and as much functional programming as possible. Let's see how this will end up in the following blog post.
    </p>
  hrefs:
    f: https://gist.github.com/kurbaitis/c81e65a1f8b1b3e86405
'2015-09-22':
  text: >
    Tonight I've released the dev version of my experiment. Well it's probably not working so good when it comes to installation, but the point is not here this time. I'd like to share some thoughts where this project is going to. You can check out the V3 <a href='https://github.com/kurbaitis/hosting' target='_blank'>here</a>.

    <h2>Some changes</h2>
    
    Like I've mentioned in the last blog post, I'm trying to apply as much functional programming as possible everywhere, at least in syntax level. There are some issues with 3rd parties and edge cases handling, but these are temporary issues as currently I'm focusing more on architectural decisions. Hopefully, this experiment will grow up to something better in the future as I've started to implement such things as Router pattern, Vhosts and so on. Basically, it should be everything what a simple website developer wants to have at the first stage of his/her project.

    <h2>TODOs</h2>

    In short, currently it's hard to say when I have enough time to polish all the project but at the moment some core architecture things are getting brighter each day. Although I'm happy with the process, there are some issues to solve: 3rd parties connection fixes, error reporting, metrics engine, easier installation and so on. If this gonna succeed, the project should turn into a new Ruby framework with various modules available to connect. Quite big objective, but luckily I'm still in a new job search.

  hrefs:
    
'2015-09-23':
  text: >
    Any setup of a system should be easy. Not too much text about it and just inputs that you really need. Ideally, just the inputs about 3rd parties (payments system, reporting etc.) The inputs can be various: HTTP Basic authentication credentials, OAuth client id and secret or some other values like URL, a string. 

    <h2>The flow</h2>
    
    The flow of your setup script should be in order. I use this: OS libs, source archives directly from creator's mirror, other dependencies install. For source archives I use <a href='http://curl.haxx.se' target='_blank'>curl</a> command which fetches the list of archives that are available, then takes the latest version with the most efficient compression format. Knowing the URL, you can fetch the archive, extract and build. In Ruby case, you need to install required gems for your application, maybe do some configuration and login yourself to the user where the bin/start script exists. In some cases, this is not needed, for instance, if you want to setup your application to run at boot time.
    
    <h2>Setup script</h2>
    
    If you're working on Unix, prefer default Shell (usually /bin/bash) for the script, probably not so much issues in the future. Don't forget to define requirements in your app's README for the system where the setup will run, this will save some time too for other developers. 
   
    <h2>Example</h2>
    
    This is the [setup script][ss] from one of my created applications.
    
    <p>
      The script asks you to provide tty with root pasword and executes all the commands. Anyway, this is very relative to what you do and what technologies use. Hopefully, this will help someone to build easier to start applications. Cheers.
    </p>

  hrefs:
   ss: https://gist.github.com/kurbaitis/f8b33b4d82235960689f
'2015-09-25':
  text: >
    <a href='https://en.wikipedia.org/wiki/Relational_database_management_system' target='_blank'>RDBMS</a> is a concept which is about sophisticated data store. Everything here is about relations, you can even define the level of security by defining constraints for particular data tables. However, everything has its own price (CPU in this case) and this is where <a href='https://en.wikipedia.org/wiki/NoSQL' target='_blank'>NoSQL</a> wins. Looking from the security perspective, RDBMS is the right tool for finance, banking business as it supports transactions with locking I/O while a transaction is in process. Anyway, this blog post is about optimization of RDBMS when it comes to input.

    <h2>Current tools</h2>
      
    There are a lot of RDBMS based software, you can check it out <a href='https://en.wikipedia.org/wiki/List_of_relational_database_management_systems' target='_blank'>here</a>. The most popular ones are <a href='https://www.mysql.com' target='_blank'>MySQL</a> and <a href='http://www.postgresql.org' target='_blank'>PostgreSQL</a> in open source community. The issue with all of these is the variaty of supported methods of input. Well ok, using bash you can easily export/import, but when it comes to application level usage, this is getting fuzzier. Let me give you an example.
    
    <p>
      I like PostgreSQL which has <a href='http://www.postgresql.org/docs/current/static/sql-prepare.html' target='_blank'>Prepared Statements</a> function. Although everyone usually use default SQL queries to reach the data, it's not efficient. For prototypes it works, but not for production applications. So if you're using any RDBMS software, please be aware of I/O optimization when it's needed.
    </p>

    <h2>Prepared Statements</h2>
      
    PostgeSQL supports a lot of ways to input your data to a database. COPY, INSERT, Bash interface etc. Well, about 5 years ago, I've been searching for a proper way to input updated data to my database and the requirement was to make it as efficient as possible for high load. This is where Prepared Statements comes into the play.
    
    <p>
      The principle is simple: by using Prepared Statements you create a framework of all the dependencies for the query and when you call the query, it just use the cached framework with your sent data. This is like a trade-off between your resources: you pay more memory and save CPU.
    </p>

    <h2>Implementation</h2>
    
    In Ruby it's simple if you use <a href='http://sequel.jeremyevans.net' target='_blank'>Sequel</a>. At that time, I used the newest version of it, now it's a bit outdated, but I'm sure they have similar interface for this function in the newest version. [The example][e]:
    
    <h2>Sum up</h2>
    
    Actually, I've created an extension for Sequel for automated prepared statements creation, so it's possible just to make it work by default in Sequel. Hopefully, one day I'll release it, but for now I'm more focused to my experiment. Happy investigation!

  hrefs:
    e: https://gist.github.com/kurbaitis/f5387059177c13768a1a    
'2015-09-27':
  text: >
    This blog post is about legacy apps fixing when it comes to memory leaking. For instance, you have an old application, maybe a new one, which is leaking memory, then starts filling swap memory and in the end your server goes down. I found a solution which works in my case. So my app is based on <a href='https://en.wikipedia.org/wiki/Merb' target='_blank'>Merb v1.1.3</a> (Ruby) and although this framework was merged to Rails long time ago, it still has power to run these days with some minor gems changes. Well, some of gems that Merb consists of were needed to be moved to lib/ and make some modifications too. Anyway, the solution works for any kind of application which is leaking memory.

    <h2>How it works</h2>
    
    In my case, luckily, the application is not too big and it manages to boot in 1-2 seconds. Then the memory usage starts to grow until it fills in all available gaps and the server goes down. So to solve this, I've created a script which reboots the application each 10 seconds. Funny, but this is a trade-off between memory and CPU + I/O. By doing this, application works but with timeouts as it needs some time to boot the app each time. Well, then you need a proxy, which checks if app is running and only then forwards visitors to the application where the visitors' requests are really processed.
    
    <h2>Implementation</h2>

    The start script is simple in my case, you can use watch command which exists in Unix, but I've done it like [this][t].
    <br /><br />
    The next part is <a href='http://www.haproxy.org' target='_blank'>HAproxy</a>, which is a proxy server for any kind of connections. Look at this [configuration file][f].
    
    <p>
      This file defines that the proxy is running on any network interface, forwards the requests to your application (127.0.0.0 means localhost) and if the application doesn't respond, the proxy waits for 10 seconds before returning timeout error template to visitor's browser if the application is not responding during that time. Note: HAproxy installed directly from your OS package manager is accessible only using root access.
    </p>

    <h2>Combining it together</h2>
    
    This solution is still not ideal when it comes to other dependencies that your legacy app might use. For instance, caching servers and so on. This needs nighly reboot of your server to cope with that by one take. If doing so, please don't forget to use boot scripts to initialize all required dependencies after restart.
    <br /><br />
   
    For instance, my legacy app's [boot script][s].
    
    <p>
      To apply the script to your server, you need to run this as root in your shell:
    </p>
    
    ```update-rc.d script-name defaults```
    <br />
    ```update-rc.d script-name enable```
 
    <h2>Sum up</h2>
    
    This is just a sample solution that works for my case. There are other solutions, for instance, one of them comes together with default Ruby implementation (MRI). WEBrick also supports proxy servers but I haven't managed to make it work instantly, probably some headers or environment variables are not correct. You could use also SSH tunnel to proxy connections to your application but it has some issues with timeout configuration. Good luck choosing the right one for yourself!

  hrefs:
    t: https://gist.github.com/kurbaitis/629a0d5c99384d111f70
    f: https://gist.github.com/kurbaitis/aa3a6163c1217e7a6c13
    s: https://gist.github.com/kurbaitis/c5fa920087b3fe58b9a5
'2015-09-30':
  text: >
    Today is a happy day for me because I've just released a new version of games-monitor.net which includes a lot of fixes and improvements. It's still buggy due to existing dependencies but I'm fixing that. The project was started in 2008 but due to improved knowledge in Bash I managed to fix major performance issues by trading off server resources. In this blog post I'll share some solutions that helped me to fix this legacy project.

    <h2>Background jobs</h2>
    
    The problem with memory leaking systems is that you have to use native OS processes (<a href='http://ruby-doc.org/core-2.2.3/Kernel.html#method-i-fork' target='_blank'>Kernel#fork</a>) to do the memory leaking work and then quit the process. The main process manages the flow of child processes (where the work is done) in the system but that's not a problem because it's possible to reboot the main process too. For my project I use <a href='https://github.com/resque/resque' target='_blank'>Resque</a> gem which implements this kind of solution.
    
    <h2>One direction</h2>

    If you use background jobs, then better use it for all blocking tasks in your system. For instance, the adding of servers into the list was dedicated to the HTTP application which is not efficient. I managed to fix it by pushing that jobs to Resque. The implementation of this solution is a bit tricky as the client still needs to know about the success of the request. This was done in [this way][w].
    
    <p>
      First of all, you need a reference which couples your background job with the website's application. So to inform the application if job is successful, you need to use some kind of cache which is being checked each second to know if the server has been updated. If it is, the result is the ID of the server, if not, the result is 0.
    </p>
    
    <h2>Queries caching</h2>
    
    Probably <a href='http://www.postgresql.org' target='_blank'>PostgreSQL</a> supports some kind of queries caching, but for now I made it work simple by using <a href='http://redis.io' target='_blank'>Redis</a>. This allows to implement simple search in the website without a lot of I/O blocking. It's still not ideal but for now it works keeping in mind the DB size and search scope. If DB grows, then it will be time to implement more advanced full text search engine.
    
    <h2>Error reporting</h2>
    
    I'm quite confident about this release when it comes to errors, so instead of using email notifications, I added error reporting to my mobile phone. Thanks to <a href='https://www.twilio.com' target='_blank'>Twilio</a> which allows to send any kind of data to mobile phone.
    
    <h2>Sum up</h2>
    
    Like I've mentioned, there are a lot of dependencies to trash in the system. For key-value store, could work <a href='http://www.gnu.org.ua/software/gdbm' target='_blank'>GNU gdm</a>, for background jobs just simple bash script and so on. Anyway, hopefully this helps anyone fixing legacy systems. Cheers.

  hrefs:
    w: https://gist.github.com/kurbaitis/04ad6027b19fea8a54d6
'2015-11-08':
  text: >
    [Jekyll][j] is a powerful tool for static HTTP webpages. The concept is that you generate content dynamically on your local machine and push the result to your hosting. It can work well on any hosting provider platform. The content itself must be static though. In this short blog post I'll share some ideas how it started to work like I want.
    
    <h2>Posting</h2>

    Posting should be fun and easy. This is why I created an executable for my posting process. It creates post files and stores all data in one data file. I dislike when data is distributed among a lot of files. Maybe you think different and that's ok, less complications with the default jekyll approach.
    
    Jekyll supports data storing in various formats, I like ```.yml``` so I decided to put there my posts data and call it ```_data/posts.yml```. The format of that data is simple:
    <br /><br />
    1. date in YYYY-mm-dd format as a key
    <br />
    2. post text as a part of value
    <br />
    3. hrefs with urls (key-value) used for links in post text as a part of value
    <br /><br />

    [Here][h] it is the ```bin/post``` file which should be run like this: ```bash bin/post "The title of your new post"```. This script eases the creation of post at least for me, because after entering the blog post title you get to the file where your post information will be stored. The interface for that is  Vim. After completing the writing part you're redirected to shell where your jekyll boots up. 
   
    <h2>Publishing</h2>
    
    Publishing your ```_site``` directory where the static content is generated is a bit tricky when it comes to Github Pages. In other words, if you aren't using Github, you can direct traffic to ```_site``` directory where any visitor will see the same result.
    <br /><br />
    If you're using Github Pages, please be aware that you need to push your ```_site``` directory to ```gh-pages``` branch. So this is totally not in sync with your master branch where the actual your content for generation is being kept.
    <br /><br />
    There is a work around for this situation when it comes to Git. You can use this executable [here][h2].

    <h2>Some thoughts for future</h2>
   
    It would be nice to have working code highlighting in V3 of Jekyll. The default markdown is [kramdown][k] which is not working as expected if using ```_includes``` directory contents. Anyway, for now Github Gists is working good. Hopefully, Jekyll won't stop improving as I like it so much.

  hrefs:
    j: https://jekyllrb.com
    k: http://kramdown.gettalong.org
    h: https://gist.github.com/kurbaitis/210bb198a573026f301f
    h2: https://gist.github.com/kurbaitis/728d6fb551be21450659 
'2015-11-13':
  text: >
    Today while working on one of my personal projects (legacy) I came across outdated caching which was the main reason 
    why the site was not correctly working. Some fixes are needed, but due to the lack of time I'm 
    gonna close the project. Anyway, while trying to fix it I wrote a simple caching tool for partials that are String 
    object type of course.

    <h2>The idea</h2>

    The idea is simple, you need two keys for key-value based caching systems: one for expiration and one for actual data. 
    The data in my case were partials that exist in Rails/Merb views. Using expiration time you set deadline for 
    regeneration of the content. This task goes to some random visitor if using this implementation without background jobs.
    If it's relatively fast, it won't be a problem because to make a site work fluently all the time, it costs 
    a lot of development work.

    <h2>The implementation</h2>

    You can checkout this [gist][g] and comment please. As always, I'm rushing to publish my code examples, don't hesitate to modify it. Cheers. 
  hrefs:
    g: https://gist.github.com/kurbaitis/eba1370522c01aac292a
'2015-11-19':
  text: >
    WEBrick is the default Ruby MRI implementation HTTP(S) server. Clearly, it's supposed to work for development environment on developers' local machines.
    While doing my experimental hosting services framework, I got into question, why.

    <h2>Advantages and disadvantages</h2>
   
    Throughput should be one of the most important parameters while choosing the right HTTP(S) server. Unfortunatelly, WEBrich lost this fight when fighting alone.
    It just starts closing connections while doing its work unexpectedly with HTTP error code.
    
    <br /><br />
    
    Although I like how WEBrick has been builded due to bipolar function: it's web server and web framework. Two functions inside it.
    The second one I like very much, but probably will have to give up it as I need to solve the throughput issue. 
    The solution would be load balancer like I mentioned in [earlier post][e]. Currently [the experiment][ex] is working like explained with HAproxy.
    
    <br /><br />
    
    One more issue is memory leaking which is obvious. I'm gonna play with that to find solution from application level.
    Maybe no need to use bash script to kill application's process and spawn a new one regularly.
    
    <br /><br />

    The last issue which made me sad was TLS configuration which is awful in WEBrick. You have to do hacks to set ciphers and so on. With HAproxy it's much easier.

    <h2>Sum up</h2>

    Currently I'm just playing with various solutions for WEBrick to work well. If you don't want to do this, better just use other kind of HTTP(S) server. 
    I'd prefer [Passenger][p] which can work in standalone mode too. It allows to respawn a process handling connections by given limit of
    connections served or, if you have enterprise edition, just by memory amount. Anyway, v4 of the experiment is on its way.
  
  hrefs:
    e: /2015/09/27/Legacy-apps-fix.html
    ex: https://github.com/kurbaitis/hosting
    p: https://www.phusionpassenger.com/
'2015-11-22':
  text: >
    Finally, the v4 of my game hosting engine is done. The changes applied is not too big comparing to v3 but still some problems solved using external than Ruby libraries. 
    More precisely, TLS issue has been solved using HAproxy. Although it works on WEBrick, HAproxy ensures nice load balancing and waits if WEBrick is not 
    capable to ensure higher load.

    <h2>The business idea</h2>

    I was thinking to make not just demo, but working version of this kind of service but have to confess, today's market is fulfilled with similar services and 
    better prices than I could offer. Anyway, the demo version will be working for some time online and loayal visitors of ```http://games-monitor.net``` 
    can see the offer to create their own game servers hosting if they can be a good player in today's game hosting services market. 
    I even can help then to make it work if there is such a need.

    <h2>What I got from this experiment?</h2>

    Each personal project, no matter what, gives me some particular knowledge in the technology from which the project has been made. 
    This time it was TLS protocol and HTTP(S) servers analysis. Hopefully, soon I'll decide to push some of my time to some kind of new product creation 
    as I feel that v4 is enough for current working project. Visit it [here][h] please if interested. Cheers.
  hrefs:
    h: https://hosting.games-monitor.net
'2015-11-29':
  text: >
    Lately, I've been digging into my old code and realised that, luckily, there are some stuff to review and publish into this blog. Bayesian rating helped me to keep balance in one of my project's rating system. In this blog post I'll review it from practical side with some Ruby based testing.

    <h2>The problem</h2>

    The problem with rating came to my mind when I saw that rating system based on averages is not working when it comes to quantity of votes. If you have one high vote for a product and another product with 100 votes that are a bit mixed with values, but also high, which one should go first in the rating list?
    <br /><br />
    
    If you take this example to larger scale, the problem becomes a serious threat to your credibility against your clients. Everyone wants to see rating interpreted correctly, including popularity too and developers goal is to make that happen. [IMDb][imdb] uses Bayesian too to determine its Top 250.
    
    <h2>The Bayesian rating formula</h2>
    
    `(WR) = (v ÷ (v+m)) × R + (m ÷ (v+m)) × C`
    <br /><br />
    
    It consists from:
    
    <ul>
      <li>R = average for the object (mean) = (Rating)</li>
      <li>v = number of votes for the object = (votes)</li>
      <li>m = minimum votes required to be listed in the list (in the test script it is equal to 1)</li>
      <li>C = the mean vote across the whole objects</li>
    </ul>

    <h2>Test</h2>

    There are various formulas and theories how to make rating work like you need, but I choose Bayesian rating system as it gives all what I need: the factor of quantity gets into the logic of rank calculation. It's a precious operation, so better it works in background, non-blocking your customer user experience each time he/she wants to see the results. It's possible to make the calculation inside SQL too if you know how to do it and it works better for your system architecture.
    <br /><br />

    [Here][h] is the test written in Ruby, the output is [here][h2]. I'll leave the judgment of results to you.

    <h2>Sum up</h2>

    For my project this was working good, you can even make some experiments by changing median value to other aggregated number. As you understand, this leaves some space for customisation for your needs. I'd recommend to play with it and see what results are produced by doing the experiments. You have the starting point of your script, good luck!
  hrefs:
    h: https://gist.github.com/kurbaitis/c212f824e2fcda86af80
    h2: https://gist.github.com/kurbaitis/5b6388d2e6f47320cbc8
    imdb: http://www.imdb.com
